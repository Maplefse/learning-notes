# 微服务

## 微服务是什么?

要搞清楚微服务，首先要了解集群与分布式这两个概念

### 集群是什么？

- 通过多台计算机去完成同一项工作，以获取更高的运行效率
- 多台计算机，工作相同，如果其中一台发生意外死机。另一台依旧可以继续执行

优点在于：本来一台服务器处理所有操作，如果访问数据过大可能造成系统崩溃、死机等各种问题。这种情况下，升级硬件就代表着更多的花费（一台顶配服务器肯定是比两台中配服务器贵的）通过集群将压力分担到其它的服务器上起到1+1=2的作用。即使其中一个出现异常，依旧有其它的服务器可以继续运行。

一句话概括就是：**同一个业务，部署在多个服务器上。它们同时执行这个业务的功能**

### 分布式是什么？

- 将一个业务的不同模块分布放到不同的服务器上，在使用的时候它们再互相通信组合成一个完整的业务

优点在于：

1. 模块之间独立，一个模块只负责自己的功能，便于扩展与复用。
2. 可以更好的利用服务器资源。例如现在有两台服务器，一台配置较高，一台配置较低。就可以使用分布式，将系统中访问量高的功能放在配置高的服务器中，访问量较低的功能放在配置低的服务器中。
3. 高吞吐量。某个任务需要10个小时去执行，将这个任务用多台服务器进行分布式操作，有效减少运行时间。

一句话概括：**将一个业务的功能进行拆分，不同的功能放到不同的服务器上运行。**来完成一个完整的业务功能

### 微服务

而微服务就是一种经过良好架构设计的分布式架构方案，微服务的架构特征：

- 单一职责：微服务拆分粒度更小，每一个服务都对应唯一的业务能力，做到单一职责。避免重复的业务开发
- 面向服务：微服务对外暴露业务接口，方便其它服务对其进行业务之间的通信。
- 自治：团队独立、技术独立、速度独立、部署独立
- 隔离性强：服务调用做好隔离、容错、降级，避免出现级联问题



## 上手demo

首先，获得一个最基础的spring项目（项目地址：https://pan.baidu.com/s/169SFtYEvel44hRJhmFTRTQ	提取码：1234）

![image-20220222234206504](assets\image-20220222234206504.png)

在cloud-demo项目下，有两个子项目，子项目被分别管理并有各自的数据库与端口。

**order的功能**

```java
@RestController
@RequestMapping("order")
public class OrderController {

   @Autowired
   private OrderService orderService;

    @GetMapping("{orderId}")
    public Order queryOrderByUserId(@PathVariable("orderId") Long orderId) {
        // 根据id查询订单并返回
        return orderService.queryOrderById(orderId);
    }
}
```

**user的功能**

```java
@Slf4j
@RestController
@RequestMapping("/user")
public class UserController {

    @Autowired
    private UserService userService;

    /**
     * 路径： /user/110
     *
     * @param id 用户id
     * @return 用户
     */
    @GetMapping("/{id}")
    public User queryById(@PathVariable("id") Long id) {
        return userService.queryById(id);
    }
}
```

### 启动项目

![image-20220222234609745](assets\image-20220222234609745.png)访问成功即可得到各自接口查询出的数据

## 服务远程调用

现在，功能需求在查询order订单的时候同时获取到用户的数据。

在单体架构中，一般的逻辑为：在订单接口增加一条查询用户的sql，将结果拼接返回即可。但在微服务中要求我们做到单一职责，避免重复的业务开发。既然user项目已经负责用户的查询，且order项目只应该对order的需求负责。因此只需要在order项目对user项目的接口进行远程调用，获取到user信息即可

**如何远程调用？**

### RestTemplate即可帮助实现远程调用功能

在order的启动类中注入RestTemplate

```java
@MapperScan("cn.itcast.order.mapper")
@SpringBootApplication
public class OrderApplication {

    public static void main(String[] args) {
        SpringApplication.run(OrderApplication.class, args);
    }

    /**
     * 创建RestTemplate并输入Spring
     * @return
     */
    @Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }

}
```

然后修改order接口的功能

```java
public Order queryOrderById(Long orderId) {
    // 1.查询订单
    Order order = orderMapper.findById(orderId);
    // 2.利用查询出的order信息获取user信息
    //restTemplate发送get与post请求调用get/postForObject方法即可
    //它需要两个参数:1.url地址,2.返回数据格式(json、对象等）
    String url = "http://localhost:8081/user/"+ order.getUserId();
    User userObject = restTemplate.getForObject(url, User.class);
    order.setUser(userObject);
    // 4.返回
    return order;
}
```

重启项目，再次访问order接口

![image-20220223000559612](assets\image-20220223000559612.png)

正确的获取到user的数据

### 远程调用的一些概念

提供者与消费者

- 服务提供者：一次业务中，被其它微服务调用的服务。（提供接口给其它服务）
- 服务消费者：一次业务中，调用其它微服务的服务。（调用其它微服务提供的接口）

举例：A服务调用B服务，B服务再调用C服务，那么B服务到底是什么身份？

答：**B服务既是提供者也是消费者**，它对于A是提供者，对于C则是消费者。所以一个服务的角色是**相对**的，且并不冲突！



# Eureka

## Eureka是什么?

- Eureka是[Netflix](https://baike.baidu.com/item/Netflix/662557)开发的服务发现框架，本身是一个基于[REST](https://baike.baidu.com/item/REST/6330506)的服务，主要用于定位运行在AWS域中的中间层服务，以达到负载均衡和中间层服务故障转移的目的。

Eureka有什么用?

- Eureka包含两个组件：Eureka Server和Eureka Client。
  - Eureka Server提供服务注册服务，各个节点启动后，会在Eureka Server中进行注册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到，并可以使消费者获取到其中的信息。
  - Eureka Client是一个[java](https://baike.baidu.com/item/java/85979)客户端，用于简化与Eureka Server的交互，客户端同时也就是一个内置的、使用轮询(round-robin)负载算法的[负载均衡器](https://baike.baidu.com/item/负载均衡器/8852239)。
- 消费者如何获取服务提供者具体信息？
  - 服务提供者启动时向eureka注册自己的信息，并保存
  - 消费者根据服务名称向eureka拉取提供者的信息
- 如果多个服务提供者，消费者会如何选择？
  - 消费者利用负载均衡算法，从服务列表中挑选
- 消费者如何感知服务提供者的状态？
  - 服务提供者每隔30秒向EurekaService发送心跳请求，报告健康状态
  - eureka会更新纪录服务列表信息，心跳不正常会被剔除
  - 消费者则正确拉取到最新的信息

## 搭建Eureka服务



1. ![image-20220224011342567](assets\image-20220224011342567.png)在项目中新建一个eureka-service子项目（new -> Module... -> Maven ->Next -> 命名 -> Finish)

2. 在eureka-service的pom.xml配置中添加eureka的配置信息

   ```xml
   <dependencies>
       <dependency>
           <groupId>org.springframework.cloud</groupId>
           <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
       </dependency>
   </dependencies>
   ```

3. 创建main函数

   ![image-20220224012109728](assets\image-20220224012109728.png)

   ```java
   @EnableEurekaServer
   @SpringBootApplication
   public class EurekaApplication {
   
       public static void main(String[] args) {
           SpringApplication.run(EurekaApplication.class,args);
       }
   
   }
   ```

4. 编写yml配置文件

   ```yaml
   server:
     port: 8082  # 服务端口
   spring:
     application:
       name: eurekaserver
   eureka:
     client:
       service-url:  # eureka的地址信息
         defaultZone: http://127.0.0.1:8082/eureka
   ```

5. 启动并访问Eureka端口，可以看到如下页面，证明配置成功。

   ![image-20220224012707377](assets\image-20220224012707377.png)

   


## 服务注册

现在，将user与order的服务注册到Eureka客户端中

1. 在服务端添加Eureka依赖

   ```xml
   <!--Eureka客户端依赖-->
   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
   </dependency>
   ```

2. 添加eureka配置到yml文件

   ```yaml
   spring:
     application:
       name: userserver	# user服务的服务名称
   eureka:
     client:
       service-url:  # eureka的地址信息
         defaultZone: http://127.0.0.1:8082/eureka
   ```

3. 将服务多次启动

   可以通过IDEA将服务多次启动，模拟多实例部署，但为了避免端口冲突，需要修改端口设置

   ![image-20220225000325246](assets\image-20220225000325246.png)修改完成后即可在Services中看到新增的服务![image-20220225000620351](assets\image-20220225000620351.png)将其启动

4. 将其启动，在Eureka页面查看即可发现user拥有两个实例

   ![image-20220225000842142](assets\image-20220225000842142.png)

## 服务发现

**通过order-service完成服务拉取**

服务拉取是基于服务名称获取服务列表，然后对服务列表做负载均衡

1. 修改OrderService类的代码，修改访问的url路径，使用服务器名代替ip与端口

   ```java
   //String url = "http://localhost:8081/user/"+ order.getUserId(); 旧
   //替换为
   String url = "http://userserver:8081/user/"+ order.getUserId();		
   //也就是user服务在yml中编写的userserver这个服务名称
   ```

2. 在order-service项目的启动类的RestTemplat上添加负载均衡注解

   ```java
   @Bean
   @LoadBalanced
   public RestTemplate restTemplate(){
       return new RestTemplate();
   }
   ```

3. 重启order服务，并进行访问，通过观察user的两个实例日志即可发现。order会实现负载均衡对user的两个实例进行轮询操作。



## Ribbon负载均衡

SpringCloud中自带了一个叫Ribbon的组件帮我们实现负载均衡

示意流程图

![image-20220225002531276](assets\image-20220225002531276.png)

![image-20220316002909445](assets\image-20220316002909445.png)

通过上图可以发现，IRule接口决定了负载均衡的策略。

以下是一些常见的继承IRule接口的轮询规则

### Ribbon负载均衡策略![image-20220316003133808](assets\image-20220316003133808.png)

Ribbon默认使用RoundRobinRule作为轮询的策略。

当我们想要使用其它的负载均衡策略改如何处理？

1. 代码方式：在order-service中的启动类中定义一个新的IRule

   ```java
   /**
    * 定义reandomRule作为轮询策略
    * 注意：在这里定义的策略作用于全局，不管order以后访问其它任何接口，都会使用这个轮询策略
    * @return
    */
   @Bean
   public IRule randomRule(){
       return new RandomRule();
   }
   ```

2. 配置文件方式：在order-service的application.yml文件中添加负载均衡规则的配置

   ```yaml
   userserver: #需要定义规则的端口号
     ribbon:
       NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #定义负载均衡的规则
       
   #通过这种方式,可以对某个固定的端口号进行特定的负载均衡方式
   ```

配置完成后重启项目，多次访问接口，查看是否是随机对两个端口进行访问，如果是则证明配置成功。

### Ribbon懒加载与饥饿加载

Ribbon默认使用懒加载，即第一次访问时才会去创建LoadBalanceClient，请求时间会很长。而饥饿加载则会在项目启动时创建，降低第一次访问的耗时，通过下面的配置开启饥饿加载

```yaml
ribbon:
	eager-load:
		enabled: true # 开启饥饿加载
		clients: userserver # 指定对userserver服务进行饥饿加载
		
		#clients:		这种写法可以指定多个服务进行饥饿加载
		# - userserver
		# - userserver
```



# Nacos

首先先在电脑上安装Nacos

Nacos[安装教程](D:\学习文档\SpringCloud\资料\Nacos安装指南.md)

## 使用Nacos

1. 在父工程中添加Nacos的依赖

   ```xml
   <dependency>
       <groupId>com.alibaba.cloud</groupId>
       <artifactId>spring-cloud-alibaba-dependencies</artifactId>
       <version>2.2.5.RELEASE</version>
       <type>pom</type>
       <scope>import</scope>
   </dependency>
   ```

   

2. 在子工程(客户端)添加Nacos依赖(order与user都要)

   ```xml
   <!-- nacos客户端依赖包 -->
   <dependency>
       <groupId>com.alibaba.cloud</groupId>
       <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
   </dependency>
   <!-- 记得注释Eureka依赖 -->
   ```

   

3. 在配置文件application.yml中添加Nacos的配置

   ```yaml
   spring:
     cloud:
       nacos:
         server-addr: localhost:8848 # Nacos服务地址
   # 同样记得注释Eureka依赖
   ```

   

4. 全部修改完成即可启动服务，无需修改代码。测试Nacos是否生效

5. 访问Nacos控制台，查看服务列表![image-20220321000409903](assets\image-20220321000409903.png)能够正确看到order与user两个服务即证明服务注册成功，访问oredr接口，正常运行无误证明配置无误。



## Nacos服务分级存储模型

在大型项目中，服务器为了安全考虑，通常会在通常会在不同的地区配置机房（可以简单的将一个地区的服务器称作一个**集群**），防止突发性的停电、断网等意外。即使一个地区的服务器宕机，还有另一个地区的服务器做保障。

而然而对比本地访问，两个不同地区的服务器相互访问，肯定会因为远距离访问或网络原因出现延迟等问题。为此要尽可能的避免跨集群的访问，只有本地集群不可用时，再去访问其它的集群。

Nacos配置集群属性

1. 修改application.yml，添加以下内容

   ```压马路\
   spring:  
     cloud:
       nacos:
         server-addr: localhost:8848 # Nacos服务地址
         discovery:
           cluster-name: GZ # 集群名称,GZ表示广州
   ```

   

2. 启动服务

   ![image-20220321002411923](assets\image-20220321002411923.png)将user1和user2启动，它们即被配置在GZ集群中

3. 我们再修改user的application.yml文件（注意：user1和user2正常运行，不要重启。测试环境才使用这种方式）

   ```yaml
   spring:  
     cloud:
       nacos:
         server-addr: localhost:8848 # Nacos服务地址
         discovery:
           cluster-name: SH # 集群名称,SH表示上海
   ```

   然后启动新创建的user3服务![image-20220321002844444](assets\image-20220321002844444.png)

4. 刷新Nacos页面即可看到

   ![image-20220321002940438](assets\image-20220321002940438.png)user服务中有两个集群![image-20220321002958406](assets\image-20220321002958406.png)分别是我们配置的GZ和SH集群

## NacosRule负载均衡

在上一步操作中，成功将不同的服务配置在不同的集群，现在我们就将实现集群优先对本地集群进行访问的功能

1. 配置order服务的application.yml，添加集群信息

   ```yaml
   spring:
     cloud:
       nacos:
         server-addr: localhost:8848 # nacos服务地址
         discovery:
           cluster-name: GZ	# 配置order为GZ集群
   ```

2. 设置order的负载均衡Rule为NacosRule，它会优先寻找与自己同集群的服务，然后随机访问

   ```yaml
   userserver: #需要定义规则的端口号
     ribbon:
       NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule # 配置负载均衡策略为NacosRule
   
   # 注意：同端口号服务配置多个负载均衡策略可能会出现异常
   ```

   

3. 启动order服务，测试负载均衡规则。配置成功可以发现，位于SH集群的user3并不会被order访问



## Nacos实例权重

正常项目部署中通常会出现如下情况

- 服务器设备性能不同，有的服务器性能较强，有的服务器性能较弱。我们需要性能强的服务器承担更多的用户请求，这时就可以通过权重来进行负载均衡，权重高的获取更多的请求。

可以在Nacos的控制台配置权重参数

![image-20220322004550571](assets\image-20220322004550571.png)权重参数一般在0-1之间，现在将8081服务的权重配置为0.1。

多次访问order接口即可发现，8081服务被访问的频率大幅减少

**将权重调整为0后，该服务则永远不会被访问！**（一般用于系统更新时，设置权限为0后进行升级操作）

## namespace环境隔离

Nacos提供了namespace来实现环境隔离功能。

- nacos可以有多个namespace
- namespace下可以有guoup、service、等
- 不同namespace之间互相隔离，无法访问，两个不同的namespace服务互不可见
- 如无配置，默认所有的service、data、guoup都在public这个默认的命名空间中

### 创建namespace

在nacos的控制台中

![image-20220322001123390](assets\image-20220322001123390.png)点击即可新建

![image-20220322001145414](assets\image-20220322001145414.png)空间名和描述必填，命名空间ID不填则用UUID自动生成，成功创建后即可看到新的命名空间

![image-20220322001252360](assets\image-20220322001252360.png)

### 配置命名空间

现在我们将orderservice配置到新建的dev命名空间中，在application.yml中添加如下配置

```yaml
  nacos:
    server-addr: localhost:8848 # nacos服务地址
    discovery:
      cluster-name: GZ
      # 新增下面一行
      namespace: f2e85c72-e2d1-4072-ada9-8cdad0f0b888   # 命名空间的id
```

配置完成重启即可在nacos的控制面板中dev的服务列表看见order服务

![image-20220322001642673](assets\image-20220322001642673.png)

这时再访问order接口即报错

> java.lang.IllegalStateException: No instances available for userserver

**因为不同namespace下的服务不可见**

# Eureka与Nacos的区别

Nacos的服务实例分为两种类型

1. 临时实例：如果实例宕机超过一定时间，会从服务列表剔除。默认的模式
2. 非临时实例：如果实例宕机，不会将服务从服务列表剔除。也叫永久实例

配置服务为永久实例

```yaml
spring:
  cloud:
    nacos:
      discovery:
        ephemeral: false # 设置为非临时实例
```

Nacos与Eureka整体结构相似、服务注册、服务拉取、心跳等待，但也存在一些差异：

![image-20220322234913554](assets\image-20220322234913554.png)

Nacos与eureka的共同点

- 都支持服务注册和服务拉取
- 都支持服务提供者心跳方式做健康检测

Nacos与eureka的不同

- Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式
- 临时实例心跳不正常会被剔除，非临时实例则不会被剔除
- Nacos支持服务列表变更的消息推送模式，服务列表更新更及时
- Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式



# Nacos配置管理

## Nacos统一配置管理

当微服务系统部署的实例越来越多，达到几十上百个的时候，一个一个的修改服务的配置就会非常的浪费时间且容易出错，这时就需要一个集中配置管理，修改一次即可修改所有的实例配置。

Nacos就可以帮助我们实现这个需求，它不仅可以将配置集中管理，另一方面可以在配置变更时，及时通知各个服务，实现配置的热更新

### 如何配置？

在Nacos的控制面板中

![image-20220323001449312](assets\image-20220323001449312.png)配置列表，点击新建

![image-20220323001839854](assets\image-20220323001839854.png)

配置好后点击发布即可。

### 从Nacos中拉取配置

Nacos配置完成后，服务要拉取Nacos中的配置，并与本地的application.yml配置合并，完成启动操作

但是还未读取到application.yal如何知道Nacos配置的地址呢?

为此spring引入了一种新的配置文件：bootstrap.yaml文件，它会在application.yml之前被读取，具体流程如下图![image-20220323002810670](assets\image-20220323002810670.png)

#### 实现步骤

1. 在user的pom.xml引入Nacos的配置管理客户端依赖

   ```yaml
   <!-- nacos配置管理依赖 -->
   <dependency>
   	<groupId>com.alibaba.cloud</groupId>
   	<artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
   </dependency>
   ```

2. 在resources目录下新建bootstrap.yml文件，添加如下配置

   ```yaml
   spring:
     application:
       name: userserver
     profiles:
       active: dev # 表示正式环境
     cloud:
       nacos:
         server-addr: localhost:8848 # nacos地址
         config:
           file-extension: yaml # 文件后缀名
           
   # 可以发现,name+active+file-extension就是我们上面创建的配置名
   # 配置完这些后,可以发现application.yml中服务名称与nacos地址的配置重复了,这时就可以选择删掉application中的相关配置
   ```

3. user的controller中添加如下代码

   ```java
   //读取Nacos的配置
   @Value("${pattern.dateformat}")
   private String dateformat;
   
   @GetMapping("now")
   public String now(){
       return LocalDateTime.now().format(DateTimeFormatter.ofPattern(dateformat));
   }
   ```

   然后启动项目, 访问now接口验证是否成功



### 实现热部署

接下来就是最终目标，配置文件的热部署，在Nacos配置面板中更改配置信息无需重启项目。

可以通过两种方式进行实现

1. 在@Vaule注入的变量中所在类上添加注解@RefreshScope

   ![image-20220323005847529](assets\image-20220323005847529.png)

2. 创建一个用于读取配置属性的实体类

   ```java
   @Data
   @Component		//将类注入到bean中
   @ConfigurationProperties(prefix = "pattern")	//这个注解会去读取配置文件
   public class PatternProperties {
   
       public String dateformat;
   }
   ```

   在其它类中直接使用即可

   ```java
   @Autowired
   private PatternProperties pattern;
   
   @GetMapping("now")
   public String now(){
       return LocalDateTime.now().format(DateTimeFormatter.ofPattern(pattern.getDateformat()));
   }
   ```



### Nacos配置共享

多环境配置共享

微服务在启动时会从nacos读取多个配置文件

1. [spring.application.name]-[spring.profiles.active].yaml，例如：userserver.dev.yaml
2. [spring.application.name].yaml，例如：userserver.yaml

无论profile如何变化，[spring.application.name].yaml这个文件都一定会被加载，因此多环境配置共享通常都写在这个文件中

#### 测试使用

1. 我们在Nacos中新增一个userserver配置

![image-20220324000232745](assets\image-20220324000232745.png)

2. 在配置实体类中添加`public String envSharedValue;`属性

3. controller层中拿取并显示

   ```java
   @GetMapping("sharedVaule")
   public String getSharedVaule(){
       System.out.println(pattern.getEnvSharedValue());
       return pattern.getEnvSharedValue();
   }
   ```

   

4. 访问接口

   ![image-20220324000430185](assets\image-20220324000430185.png)成功获取配置中的参数

当我们本地配置与远程配置拥有同一个配置属性时，到底谁的属性生效呢？

多种配置的优先级别为：

` 服务名-profile.yaml > 服务名.yaml > 本地配置`

**本地配置的优先级别最低！**、

# Nacos集群搭建

[集群搭建文档](D:\学习文档\SpringCloud\资料\nacos集群搭建.md)



# Feign

Feign是一个声明式的http客户端，相比与RestTemplate它能更优雅的实现http请求的发送

首先看RestTemplate发起远程调用的代码：

```java
String url = "http://userserver/user" + order.getUserId();
User user = restTemplate.getForObject(url, User.class);
```

它主要存在这两个问题

1. 代码可读性差，编程体验不统一
2. 参数混合在URL中，难以维护

而Feign的作用就是帮助我们优雅的实现http请求的发送，解决上面提到的问题。官方地址：https://github.com/OpenFeign/feign

## 使用Feign

1. 引入依赖

   ```xml
   <!--feign客户端依赖-->
   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-starter-openfeign</artifactId>
   </dependency>
   ```

2. 在启动类中添加Fegin注解

   ```java
   @MapperScan("cn.itcast.order.mapper")
   @SpringBootApplication
   @EnableFeignClients		//Fegin注解
   public class OrderApplication {
   
       public static void main(String[] args) {
           SpringApplication.run(OrderApplication.class, args);
       }
   
   }
   ```

3. 创建Fegin客户端

   ```java
   @FeignClient("userserver")
   public interface UserClient {
   
       @GetMapping("/user/{id}")
       User findById(@PathVariable("id") Long id);
   
   }
   ```

   这个接口的具体内容说明：

   - 这个客户端主要是基于SpringMVC的注解来声明远程调用的信息
   - userserver：调用服务名称
   - @GetMapping：get请求方式
   - /user/{id}：请求路径
   - Long id：请求参数
   - User：返回值类型

   有了这些信息，Feign就可以帮助我们发送http请求，无需自己使用RestTemplate发送请求了。

4. 测试使用

   修改原来我们order-service中的queryOrderById方法，使用Feign客户端来代替RestTemplate

   ```java
   @Autowired
   private UserClient userClient;
   
   //使用Fagin来请求
   public Order queryOrderById(Long orderId) {
       // 1.查询订单
       Order order = orderMapper.findById(orderId);
       // 2.利用查询出的order信息获取user信息
   
       //使用Feign远程调用
       User userObject = userClient.findById(order.getId());
       order.setUser(userObject);
       // 4.返回
       return order;
   }
   ```

   重启服务,访问order接口测试是否成功即可

## 自定义Feign配置

Feign可以支持很多的自定义配置，如下表所示：

| 类型                   | 作用             | 说明                                                   |
| ---------------------- | ---------------- | ------------------------------------------------------ |
| **feign.Logger.Level** | 修改日志级别     | 包含四种不同的级别：NONE、BASIC、HEADERS、FULL         |
| feign.codec.Decoder    | 响应结果的解析器 | http远程调用的结果做解析，例如解析json字符串为java对象 |
| feign.codec.Encoder    | 请求参数编码     | 将请求参数编码，便于通过http请求发送                   |
| feign. Contract        | 支持的注解格式   | 默认是SpringMVC的注解                                  |
| feign. Retryer         | 失败重试机制     | 请求失败的重试机制，默认是没有，不过会使用Ribbon的重试 |

一般情况下，默认值就能满足我们使用，最常修改的也就是日志级别，如果要自定义时，只需要创建自定义的@Bean覆盖默认Bean即可。

### 修改方式

1. 通过配置文件修改

   ```yaml
   feign:
     client:
       config:
         default:		# 使用default表示全局修改，使用服务名称则是针对某个微服务的修改
           loggerLevel: FULL	# 修改日志级别为FULL全部日志
   ```

2. 通过代码方式配置

   创建一个Feign的配置类

   ```java
   public class DefaultFeignConfiguration {
       @Bean
       public Logger.Level logLevel(){
           return Logger.Level.FULL;
       }
   
   }
   ```

   在启动类或Feign客户端类注解声明

   ```java
   //1.在启动类@EnableFeignClients注解中声明,表示全局有效
   @EnableFeignClients(defaultConfiguration = DefaultFeignConfiguration.class)
   ```

   ```java
   //2.在Feign客户端类中@FeignClient注解中声明
   @FeignClient(value = "userserver", configuration = DefaultFeignConfiguration.class)
   //表示只对这个客户端生效
   ```

   



## Feign性能优化

Feign底层的客户端实现：

- URLConnection：默认实现，不支持连接池
- Apache HttpClient：支持连接池
- OKHttp：支持连接池

因此优化Feign性能主要包括以下亮点：

1. 使用连接池代替默认的URLConnection
2. 日志级别最好使用basic或none

### Feign连接池配置

1. 引入依赖

   ```xml
   <!--引入feign的HttpClient依赖-->
   <dependency>
       <groupId>io.github.openfeign</groupId>
       <artifactId>feign-httpclient</artifactId>
   </dependency>
   ```

2. 配置连接属性与日志

   ```yaml
   feign:
     client:
       config:
         default:
           loggerLevel: BASIC # 日志级别
     httpclient:
       enabled: true # 支持httpclient的开关
       max-connections: 200 # 最大连接数
       max-connections-per-route: 50 # 单个路径的最大连接数
       # 连接数一般在正式使用中去进行压测,以得到最合适的连接数
   ```



## Feign的最佳实践

最佳实践，也可以称为最佳的实现方式、最好的使用方式

简单的使用Feign即可发现，我们消费者的Feign客户端与提供者的服务端代码十分接近

```java
//消费者
@GetMapping("/user/{id}")
User findById(@PathVariable("id") Long id);
```

```java
//提供者
@GetMapping("/{id}")
public User queryById(@PathVariable("id") Long id) {
    return userService.queryById(id);
}
```

一旦我们的接口数量变多，或有多个消费者。这些代码就会被重复的编写。

那么该如何简化这种重复的代码编写？

### 继承方式

相同的代码可以通过继承来实现共享

1. 定义一个API接口，利用定义方法，并基于SpringMVC注解做声明
2. Feign客户端和Controller都集成改接口

![image-20220327220107833](assets\image-20220327220107833.png)

优点：

- 简单
- 实现了代码共享、

缺点：

- 服务提供方与消费方代码紧耦合，一旦UserAPI发生变更，所有的子类和实现类都要变更
- 参数列表中的注解映射并不会继承，因此Controller中必须再次声明方法、参数列表与注解

### 抽取方式

将Feign的Client抽取为独立模块，并且把接口相关的POJO、Feign配置都放置到这个模块中，给所用的用户使用。

例如，将UserClient、User、Feign的默认配置都抽取到一个feign-api包中，所有微服务引用该依赖包，即可直接使用。

![image-20220327220232802](assets\image-20220327220232802.png)

#### 实现方式

实现抽取方式的步骤如下：

1. 创建一个新的module，命名为feign-api，然后引入feign的starter依赖

   ![image-20220327221010578](assets\image-20220327221010578.png)

2. 将order-service中编写的UserClient、User、DefaultFeignConfiguration都剪切到feign-api中

   ![image-20220327221621468](assets\image-20220327221621468.png)

3. 在order-service中引入feign-api的依赖

   ```xml
   <!--引入feign的统一api-->
   <dependency>
       <groupId>cn.itcast.demo</groupId>
       <artifactId>feign-api</artifactId>
       <version>1.0</version>
   </dependency>
   ```

4. 修改order-service中所有与上述三个组件有关的import部分，改成导入feign-api中的包

   ```java
   import cn.itcast.feign.pojo.User;
   import cn.itcast.feign.clients.UserClient;
   import cn.itcast.feign.config.DefaultFeignConfiguration;
   ```

5. 将feign中的类注入到order服务中

   由于我们已经将三个组件移动到feign-api的modul中，order在启动时无法跨包将这三个组件注入到spring容器中，启动会出现报错。这时有两种解决办法：

   1. order启动类中指定Feign应该扫描的包：

      ```java
      @EnableFeignClients(basePackages = "cn.itcast.feign.clients")
      ```

   2. order启动类中指定需要加载的Client接口：

      ```java
      @EnableFeignClients(clients = {UserClient.class})
      ```

      

6. 重启测试

   成功访问order接口证明配置无误



# 统一网关Gateway

Spring Cloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等响应式编程和事件流技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。

## 网关的作用

网关，顾名思义即使网络的关口，用于控制请求流量、访问权限等

网关的核心功能：

- 请求路由
  - 一切请求都必须先经过gateway，但网关不处理业务，而是根据某种规则，把请求转发到某个微服务，这个过程叫做路由。当然路由的目标服务有多个时，还需要做负载均衡。
- 权限控制
  - 网关作为微服务入口，需要校验用户是是否有请求资格，如果没有则进行拦截。
- 限流
  - 当请求流量过高时，在网关中按照下流的微服务能够接受的速度来放行请求，避免服务压力过大。

在springCloud中网关有两种实现方式：

1. gateway
2. zuul

Zuul是基于Servlet的实现，属于阻塞式编程，而SpringCloudGateway则是基于Spring5中提供的WebFlux，属于响应式编程的实现，具备更好的性能。

## 搭建网关

1. 创建新的module，引入SpringCloudGateway的依赖和nacos的服务发现依赖![image-20220327224744455](assets\image-20220327224744455.png)

   ```xml
   <!--网关-->
   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-starter-gateway</artifactId>
   </dependency>
   <!--nacos服务发现依赖-->
   <dependency>
       <groupId>com.alibaba.cloud</groupId>
       <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
   </dependency>
   ```

   

2. 编写启动类

   ```java
   @SpringBootApplication
   public class GatewayApplication {
       public static void main(String[] args) {
           SpringApplication.run(GatewayApplication.class, args);
       }
   }
   ```

   

3. 编写基础配置与路由规则

   ```yaml
   server:
     port: 10010 # 网关端口
   spring:
     application:
       name: gateway # 服务名称
     cloud:
       nacos:
         server-addr: localhost:8848 # nacos地址
       gateway:
         routes: # 网关路由配置
           - id: user-service # 路由id，自定义，只要唯一即可
             # uri: http://127.0.0.1:8081 # 路由的目标地址 http就是固定地址
             uri: lb://userserver # 路由的目标地址 lb就是负载均衡，后面跟服务名称
             predicates: # 路由断言，也就是判断请求是否符合路由规则的条件
               - Path=/user/** # 这个是按照路径匹配，只要以/user/开头就符合要求,将请求路由到uri的路径上去
   ```

   本例中，我们将 `/user/**`开头的请求，代理到`lb://userservice`，lb是负载均衡，根据服务名拉取服务列表，实现负载均衡。

4. 启动Gateway服务,访问`http://localhost:10010/user/1`,返回正确结果证明配置无误

5. 网络的访问流程如下

   ![image-20220327230647305](assets\image-20220327230647305.png)

## 路由断言工厂

我们在配置文件中写的断言规则只是字符串，这些字符串会被Predicate Factory读取并处理，转变为路由判断的条件

例如Path=/user/**是按照路径匹配，这个规则是由`org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory`类来处理的，像这样的断言工厂在SpringCloudGateway还有十几个:

| **名称**   | **说明**                       | **示例**                                                     |
| ---------- | ------------------------------ | ------------------------------------------------------------ |
| After      | 是某个时间点后的请求           | - After=2037-01-20T17:42:47.789-07:00[America/Denver]        |
| Before     | 是某个时间点之前的请求         | - Before=2031-04-13T15:14:47.433+08:00[Asia/Shanghai]        |
| Between    | 是某两个时间点之前的请求       | - Between=2037-01-20T17:42:47.789-07:00[America/Denver], 2037-01-21T17:42:47.789-07:00[America/Denver] |
| Cookie     | 请求必须包含某些cookie         | - Cookie=chocolate, ch.p                                     |
| Header     | 请求必须包含某些header         | - Header=X-Request-Id, \d+                                   |
| Host       | 请求必须是访问某个host（域名） | - Host=**.somehost.org,**.anotherhost.org                    |
| Method     | 请求方式必须是指定方式         | - Method=GET,POST                                            |
| Path       | 请求路径必须符合指定规则       | - Path=/red/{segment},/blue/**                               |
| Query      | 请求参数必须包含指定参数       | - Query=name, Jack或者- Query=name                           |
| RemoteAddr | 请求者的ip必须是指定范围       | - RemoteAddr=192.168.1.1/24                                  |
| Weight     | 权重处理                       |                                                              |

我们只需要掌握Path这种路由工程就可以了。

## 路由过滤器

路由过滤器 GatewayFilter是网关中提供的一种过滤器，可以对进入网关的请求和微服务返回的响应做处理：![image-20220327232932373](assets\image-20220327232932373.png)

Spring提供了31种不同的路由过滤器工厂，例如：

| **名称**             | **说明**                     |
| -------------------- | ---------------------------- |
| AddRequestHeader     | 给当前请求添加一个请求头     |
| RemoveRequestHeader  | 移除请求中的一个请求头       |
| AddResponseHeader    | 给响应结果中添加一个响应头   |
| RemoveResponseHeader | 从响应结果中移除有一个响应头 |
| RequestRateLimiter   | 限制请求的流量               |

目前先以AddRequestHeader为例进行操作

> 给所有userserver的的请求添加一个请求头：Truth

1. 修改gateway的配置文件

```yaml
spring:
  cloud:
    gateway:
      routes:
      - id: user-service 
        uri: lb://userserver 
        predicates: 
        - Path=/user/** 
        filters: # 过滤器
        - AddRequestHeader=demoKey,demoValue Hello World! # 添加请求头
        #格式:- AddRequestHeader = key,value
```

2. 修改userserver的接口，拿取demoKey请求头

```java
@GetMapping("/{id}")
public User queryById(@PathVariable("id") Long id,@RequestHeader(value = "demoKey" , required = false) String demoKey) {
    System.out.println("demoKey:" + demoKey);
    return userService.queryById(id);
}

//@RequestHeader(value = "demoKey" , required = false)
//这个注解表示获取请求头中key为demoKey的参数,requird = false表示这个参数可以为空,没有这个参数则不进行获取
```

3. 重启user与gateway服务，访问user接口，控制台输出`demoKey:demoValue Hello World!`则证明配置成功!

### 全局路由过滤器

除了给某个固定服务配置过滤器外，还可以配置全局过滤器

```yaml
spring:
  cloud:
    gateway:
      routes:
      default-filters:
        - AddRequestHeader= demoKey,demoValue Hello World!
        #在gateway下,与routes同级
```

## 全局过滤器

全局过滤器和GatewayFilter的作用用于，也是处理一切进入网关的请求和微服务响应，但和路由过滤器不同的是，路由过滤器的功能是固定的31种，而全局过滤器我们则可以**自定义过滤规则**

### 实现方式

通过实现GlobalFilter接口。

```java
public interface GlobalFilter {
    /**
     *  处理当前请求，有必要的话通过{@link GatewayFilterChain}将请求交给下一个过滤器处理
     *
     * @param exchange 请求上下文，里面可以获取Request、Response等信息
     * @param chain 用来把请求委托给下一个过滤器 
     * @return {@code Mono<Void>} 返回标示当前过滤器业务结束
     */
    Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain);
}
```

在filter中编写自定义逻辑，即可实现：登录状态判断、权限校验、请求限流等功能。

现在有如下需求：

> 定义全局过滤器，拦截请求，判断请求的参数是否含有authorization，且值为admin。如果满足则放行，否则进行拦截操作

1. 在gateway中定义一个过滤器，实现GlobalFilter接口

   ```java
   /**
    * 自定义gateway全局过滤器
    *
    * @Author: fxiao
    * @Version: 2022/03/28/0:02
    */
   //@Order(0)   //设置优先级,值越小优先级越高
   @Component
   public class AuthorizeFilter implements GlobalFilter, Ordered { //也可以通过实现Ordered接口设置优先级
   
   
       @Override
       public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
           //1.获取请求参数
           ServerHttpRequest request = exchange.getRequest();
           MultiValueMap<String, String> queryParams = request.getQueryParams();
           //2.获取参数中的authorization
           String auth = queryParams.getFirst("authorization");
           //3.判断参数值是否等于admin
           if ("admin".equals(auth)){
               //4.是->放行
               return chain.filter(exchange);  //返回这个表示放行,往下一个过滤器走
           }
   
           //5.否->拦截
           //5.1设置状态码
           exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED);//添加一个枚举参数作为返回状态
           return exchange.getResponse().setComplete();    //返回这个表示拦截
       }
   
       @Override
       public int getOrder() {
           return 0;       //返回值为优先级,值越小优先级越高
       }
   }
   ```

   

2. 重启gateway，访问接口

   ![image-20220328001506579](assets\image-20220328001506579.png)

   可以发现，只有在参数中有authorization，且值为admin才能成功访问，否则返回401



## 过滤器执行顺序

请求进入gateway网关会碰到三种过滤器：当前路由的过滤器、DefaultFilter、GlobalFilter。

请求路由后，会将当前路由过滤器和DefaultFilter、GlobalFilter，合并到一个过滤器链（集合）中，排序后依次执行每个过滤器：

![image-20220328002424514](assets\image-20220328002424514.png)

排序的规则是什么呢？

- 每一个过滤器都必须指定一个int类型的order值，**order值越小，优先级越高，执行顺序越靠前**。
- GlobalFilter通过实现Ordered接口，或者添加@Order注解来指定order值，由我们自己指定
- 路由过滤器和defaultFilter的order由Spring指定，都默认按照声明顺序从1递增。
- 当过滤器的order值一样时，会按照 defaultFilter > 路由过滤器 > GlobalFilter的顺序执行。

详细内容，可以查看源码：

`org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator#getFilters()`方法是先加载defaultFilters，然后再加载某个route的filters，然后合并。

`org.springframework.cloud.gateway.handler.FilteringWebHandler#handle()`方法会加载全局过滤器，与前面的过滤器合并后根据order排序，组织过滤器链



## Gateway网关cors跨域配置

跨域：域名不一致就是跨域，主要包括：

- 域名不同： www.taobao.com 和 www.taobao.org 和 www.jd.com 和 miaosha.jd.com
- 域名相同，端口不同：localhost:8080和localhost8081

跨域问题：浏览器禁止请求的发起者与服务端发生跨域ajax请求，请求被浏览器拦截的问题。简单来说，跨域只有在服务端请求客户端时会发生。

### 跨域问题处理

gateway网关处理跨域采用CORS方案，我们只需要简单的配置即可实现

```yaml
spring:
  cloud:
    gateway:
      # 。。。
      globalcors: # 全局的跨域处理
        add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题
        corsConfigurations:
          '[/**]':
            allowedOrigins: # 允许哪些网站的跨域请求 
              - "http://localhost:8090"
            allowedMethods: # 允许的跨域ajax的请求方式
              - "GET"
              - "POST"
              - "DELETE"
              - "PUT"
              - "OPTIONS"
            allowedHeaders: "*" # 允许在请求中携带的头信息
            allowCredentials: true # 是否允许携带cookie
            maxAge: 360000 # 这次跨域检测的有效期
```



# Docker

[Dock文档](Docker实用篇.md)



# MQ

## 同步通讯和异步通讯

微服务间通讯有同步和异步两种方式：

同步通讯：就像打电话，两方进行实时的通信

异步通讯：就像发短信，两方可以进行延迟回复

两种方式各有优劣，打电话可以立即得到响应，但是你却不能跟多个人同时通话。发送短信可以同时与多个人收发邮件，但是往往响应会有延迟。

### 同步通讯

之前学习的Feign就属于同步通讯，虽然调用可以实时的得到结果，但也会存在以下问题：

![image-20220410005322288](assets\image-20220410005322288.png)

同步调用的优点：

- 时效性较强，可以立即得到结果

同步调用的问题：

- 耦合度高
- 性能和吞吐能力下降
- 有额外的资源消耗
- 有级联失败问题

### 异步调用

我们以购买商品为例，用户支付后需要调用订单服务完成订单状态修改，调用物流服务，从仓库分配响应的库存并准备发货。

在事件模式中，支付服务是事件发布者（publisher），在支付完成后只需要发布一个支付成功的事件（event），事件中带上订单id。

订单服务和物流服务是事件订阅者（Consumer），订阅支付成功的事件，监听到事件后完成自己业务即可。

为了解除事件发布者与订阅者之间的耦合，两者并不是直接通信，而是有一个中间人（Broker）。发布者发布事件到Broker，不关心谁来订阅事件。订阅者从Broker订阅事件，不关心谁发来的消息。

![image-20220410010642928](assets\image-20220410010642928.png)

Broker 是一个像数据总线一样的东西，所有的服务要接收数据和发送数据都发到这个总线上，这个总线就像协议一样，让服务间的通讯变得标准和可控。

好处：

- 吞吐量提升：无需等待订阅者处理完成，响应更快速
- 故障隔离：服务没有直接调用，不存在级联失败问题
- 调用间没有阻塞，不会造成无效的资源占用
- 耦合度极低，每个服务都可以灵活插拔，可替换
- 流量削峰：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件

缺点：

- 架构复杂了，业务没有明显的流程线，不好管理
- 需要依赖于Broker的可靠、安全、性能

## MQ是什么？

MQ，中文是消息队列（MessageQueue），字面来看就是存放消息的队列。也就是事件驱动架构中的Broker。

比较常见的MQ实现：

- ActiveMQ
- RabbitMQ
- RocketMQ
- Kafka

几种常见MQ的对比：

|            | **RabbitMQ**            | **ActiveMQ**                   | **RocketMQ** | **Kafka**  |
| ---------- | ----------------------- | ------------------------------ | ------------ | ---------- |
| 公司/社区  | Rabbit                  | Apache                         | 阿里         | Apache     |
| 开发语言   | Erlang                  | Java                           | Java         | Scala&Java |
| 协议支持   | AMQP，XMPP，SMTP，STOMP | OpenWire,STOMP，REST,XMPP,AMQP | 自定义协议   | 自定义协议 |
| 可用性     | 高                      | 一般                           | 高           | 高         |
| 单机吞吐量 | 一般                    | 差                             | 高           | 非常高     |
| 消息延迟   | 微秒级                  | 毫秒级                         | 毫秒级       | 毫秒以内   |
| 消息可靠性 | 高                      | 一般                           | 高           | 一般       |

追求可用性：Kafka、 RocketMQ 、RabbitMQ

追求可靠性：RabbitMQ、RocketMQ

追求吞吐能力：RocketMQ、Kafka

追求消息低延迟：RabbitMQ、Kafka

## RabbitMQ消息模型

RabbitMQ官方提供了5个不同的DEMO实例，对应不同的消息模型

![image-20220410221644350](assets\image-20220410221644350.png)

RabbitMQ中的一些角色：

- publisher：生产者
- consumer：消费者
- exchange个：交换机，负责消息路由
- queue：队列，存储消息
- virtualHost：虚拟主机，隔离不同租户的exchange、queue、消息的隔离

## RabbitMQ快速上手

官方的HelloWorld是基于最基础的消息队列模型来实现的，只包括三个角色：

- publisher：消息发布者，将消息发送到队列queue
- queue：消息队列，负责接受并缓存消息
- consumer：订阅队列，处理队列中的消息

### 2.4.1.publisher实现

思路：

- 建立连接
- 创建Channel
- 声明队列
- 发送消息
- 关闭连接和channel

代码实现：

```java
package cn.itcast.mq.helloworld;

import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;
import org.junit.Test;

import java.io.IOException;
import java.util.concurrent.TimeoutException;

public class PublisherTest {
    @Test
    public void testSendMessage() throws IOException, TimeoutException {
        // 1.建立连接
        ConnectionFactory factory = new ConnectionFactory();
        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码
        factory.setHost("192.168.150.101");
        factory.setPort(5672);
        factory.setVirtualHost("/");
        factory.setUsername("itcast");
        factory.setPassword("123321");
        // 1.2.建立连接
        Connection connection = factory.newConnection();

        // 2.创建通道Channel
        Channel channel = connection.createChannel();

        // 3.创建队列
        String queueName = "simple.queue";
        channel.queueDeclare(queueName, false, false, false, null);

        // 4.发送消息
        String message = "hello, rabbitmq!";
        channel.basicPublish("", queueName, null, message.getBytes());
        System.out.println("发送消息成功：【" + message + "】");

        // 5.关闭通道和连接
        channel.close();
        connection.close();

    }
}
```

### 2.4.2.consumer实现

代码思路：

- 建立连接
- 创建Channel
- 声明队列
- 订阅消息

代码实现：

```java
package cn.itcast.mq.helloworld;

import com.rabbitmq.client.*;

import java.io.IOException;
import java.util.concurrent.TimeoutException;

public class ConsumerTest {

    public static void main(String[] args) throws IOException, TimeoutException {
        // 1.建立连接
        ConnectionFactory factory = new ConnectionFactory();
        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码
        factory.setHost("192.168.150.101");
        factory.setPort(5672);
        factory.setVirtualHost("/");
        factory.setUsername("itcast");
        factory.setPassword("123321");
        // 1.2.建立连接
        Connection connection = factory.newConnection();

        // 2.创建通道Channel
        Channel channel = connection.createChannel();

        // 3.创建队列
        String queueName = "simple.queue";
        channel.queueDeclare(queueName, false, false, false, null);

        // 4.订阅消息
        channel.basicConsume(queueName, true, new DefaultConsumer(channel){
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope,
                                       AMQP.BasicProperties properties, byte[] body) throws IOException {
                // 5.处理消息
                String message = new String(body);
                System.out.println("接收到消息：【" + message + "】");
            }
        });
        System.out.println("等待接收消息。。。。");
    }
}
```

基本消息队列的消息发送流程：

1. 建立connection
2. 创建channel
3. 利用channel声明队列
4. 利用channel向队列发送消息

基本消息队列的消息接收流程：

1. 建立connection
2. 创建channel
3. 利用channel声明队列
4. 定义consumer的消费行为handleDelivery()
5. 利用channel将消费者与队列绑定

## SpringAMQP

SpringAMQP是基于RabbitMQ封装的一套模板，并且还利用SpringBoot对其实现了自动装配，使用起来非常方便。

SpringAmqp的官方地址：https://spring.io/projects/spring-amqp

![image-20220410224125430](assets\image-20220410224125430.png)

SpringAMQP提供了三个功能：

- 自动声明队列、交换机及其绑定关系
- 基于注解的监听器模式，异步接收消息
- 封装了RabbitTemplate工具，用于发送消息

### AMQP测试使用

#### Basic Queue 简单队列模型

在父工程mq-demo中引入依赖

```xml
<!--AMQP依赖，包含RabbitMQ-->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
```

#### 消息发送

首先配置MQ地址，在publisher服务的application.yml中添加配置：

```yaml
spring:
  rabbitmq:
    host: 192.168.150.101 # 主机名
    port: 5672 # 端口
    virtual-host: / # 虚拟主机
    username: itcast # 用户名
    password: 123321 # 密码
```

然后在publisher服务中编写测试类SpringAmqpTest，并利用RabbitTemplate实现消息发送：

```java
package cn.itcast.mq.spring;

import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.junit4.SpringRunner;

@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringAmqpTest {

    @Autowired
    private RabbitTemplate rabbitTemplate;

    @Test
    public void testSimpleQueue() {
        // 队列名称
        String queueName = "simple.queue";
        // 消息
        String message = "hello, spring amqp!";
        // 发送消息
        rabbitTemplate.convertAndSend(queueName, message);
    }
}
```

#### 消息接收

首先配置MQ地址，在consumer服务的application.yml中添加配置：

```yaml
spring:
  rabbitmq:
    host: 192.168.150.101 # 主机名
    port: 5672 # 端口
    virtual-host: / # 虚拟主机
    username: itcast # 用户名
    password: 123321 # 密码
```

然后在consumer服务的`cn.itcast.mq.listener`包中新建一个类SpringRabbitListener，代码如下：

```java
package cn.itcast.mq.listener;

import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.stereotype.Component;

@Component
public class SpringRabbitListener {

    @RabbitListener(queues = "simple.queue")
    public void listenSimpleQueueMessage(String msg) throws InterruptedException {
        System.out.println("spring 消费者接收到消息：【" + msg + "】");
    }
}
```

#### 测试

启动consumer服务，然后在publisher服务中运行测试代码，发送MQ消息



### WorkQueue

Work queues，也被称为（Task queues），任务模型。简单来说就是**让多个消费者绑定到一个队列，共同消费队列中的消息**。

![image-20220410233701103](assets\image-20220410233701103.png)

当消息处理比较耗时的时候，可能生产消息的速度会远远大于消息的消费速度。长此以往，消息就会堆积越来越多，无法及时处理。

此时就可以使用work 模型，多个消费者共同处理消息处理，速度就能大大提高了。

#### 消息发送

这次我们循环发送，模拟大量消息堆积现象。

在publisher服务中的SpringAmqpTest类中添加一个测试方法：

```java
/**
     * workQueue
     * 向队列中不停发送消息，模拟消息堆积。
     */
@Test
public void testWorkQueue() throws InterruptedException {
    // 队列名称
    String queueName = "simple.queue";
    // 消息
    String message = "hello, message_";
    for (int i = 0; i < 50; i++) {
        // 发送消息
        rabbitTemplate.convertAndSend(queueName, message + i);
        Thread.sleep(20);
    }
}
```

#### 消息接收

要模拟多个消费者绑定同一个队列，我们在consumer服务的SpringRabbitListener中添加2个新的方法：

```java
@RabbitListener(queues = "simple.queue")
public void listenWorkQueue1(String msg) throws InterruptedException {
    System.out.println("消费者1接收到消息：【" + msg + "】" + LocalTime.now());
    Thread.sleep(20);
}

@RabbitListener(queues = "simple.queue")
public void listenWorkQueue2(String msg) throws InterruptedException {
    System.err.println("消费者2........接收到消息：【" + msg + "】" + LocalTime.now());
    Thread.sleep(200);
}
```

注意到这个消费者sleep了200秒，模拟任务耗时。

#### 测试

启动ConsumerApplication后，在执行publisher服务中刚刚编写的发送测试方法testWorkQueue。

可以看到消费者1很快完成了自己的25条消息。消费者2却在缓慢的处理自己的25条消息。

也就是说消息是平均分配给每个消费者，并没有考虑到消费者的处理能力。这样显然是有问题的。

#### 能者多劳

在spring中有一个简单的配置，可以解决这个问题。我们修改consumer服务的application.yml文件，添加配置：

```yaml
spring:
  rabbitmq:
    listener:
      simple:
        prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息
```

#### 总结

Work模型的使用：

- 多个消费者绑定到一个队列，同一条消息只会被一个消费者处理
- 通过设置prefetch来控制消费者预取的消息数量





## 发布/订阅

![image-20220411000010533](assets\image-20220411000010533.png)

可以看到，在订阅模型中，多了一个exchange角色，而且过程略有变化：

- Publisher：生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机）
- Exchange：交换机，图中的X。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有以下3种类型：
  - Fanout：广播，将消息交给所有绑定到交换机的队列
  - Direct：定向，把消息交给符合指定routing key 的队列
  - Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列
- Consumer：消费者，与以前一样，订阅队列，没有变化
- Queue：消息队列也与以前一样，接收消息、缓存消息。

**Exchange（交换机）只负责转发消息，不具备存储消息的能力**，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！

### FanoutExchange

Fanout，也可以称为广播

![image-20220411000718876](assets\image-20220411000718876.png)

在广播模式下，消息发送流程是这样的：

- 1） 可以有多个队列
- 2） 每个队列都要绑定到Exchange（交换机）
- 3） 生产者发送的消息，只能发送到交换机，交换机来决定要发给哪个队列，生产者无法决定
- 4） 交换机把消息发送给绑定过的所有队列
- 5） 订阅队列的消费者都能拿到消息

我们的计划是这样的：

- 创建一个交换机 itcast.fanout，类型是Fanout
- 创建两个队列fanout.queue1和fanout.queue2，绑定到交换机itcast.fanout

#### 声明队列与交换机

在consumer中创建一个类，声明队列和交换机：

```java
package cn.itcast.mq.config;

import org.springframework.amqp.core.Binding;
import org.springframework.amqp.core.BindingBuilder;
import org.springframework.amqp.core.FanoutExchange;
import org.springframework.amqp.core.Queue;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class FanoutConfig {
    /**
     * 声明交换机
     * @return Fanout类型交换机
     */
    @Bean
    public FanoutExchange fanoutExchange(){
        return new FanoutExchange("itcast.fanout");
    }

    /**
     * 第1个队列
     */
    @Bean
    public Queue fanoutQueue1(){
        return new Queue("fanout.queue1");
    }

    /**
     * 绑定队列和交换机
     */
    @Bean
    public Binding bindingQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange){
        return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange);
    }

    /**
     * 第2个队列
     */
    @Bean
    public Queue fanoutQueue2(){
        return new Queue("fanout.queue2");
    }

    /**
     * 绑定队列和交换机
     */
    @Bean
    public Binding bindingQueue2(Queue fanoutQueue2, FanoutExchange fanoutExchange){
        return BindingBuilder.bind(fanoutQueue2).to(fanoutExchange);
    }
}
```

#### 消息发送

在publisher服务的SpringAmqpTest类中添加测试方法：

```java
@Test
public void testFanoutExchange() {
    // 队列名称
    String exchangeName = "itcast.fanout";
    // 消息
    String message = "hello, everyone!";
    rabbitTemplate.convertAndSend(exchangeName, "", message);
}
```

#### 消息接收

在consumer服务的SpringRabbitListener中添加两个方法，作为消费者：

```java
@RabbitListener(queues = "fanout.queue1")
public void listenFanoutQueue1(String msg) {
    System.out.println("消费者1接收到Fanout消息：【" + msg + "】");
}

@RabbitListener(queues = "fanout.queue2")
public void listenFanoutQueue2(String msg) {
    System.out.println("消费者2接收到Fanout消息：【" + msg + "】");
}
```

交换机的作用是什么？

- 接收publisher发送的消息
- 将消息按照规则路由到与之绑定的队列
- 不能缓存消息，路由失败，消息丢失
- FanoutExchange的会将消息路由到每个绑定的队列

声明队列、交换机、绑定关系的Bean是什么？

- Queue
- FanoutExchange
- Binding



### DirectExchange

在Fanout模式中，一条消息，会被所有订阅的队列都消费。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到Direct类型的Exchange。

![image-20220411003038488](assets\image-20220411003038488.png)

在Direct模型下：

- 队列与交换机的绑定，不能是任意绑定了，而是要指定一个`RoutingKey`（路由key）
- 消息的发送方在 向 Exchange发送消息时，也必须指定消息的 `RoutingKey`。
- Exchange不再把消息交给每一个绑定的队列，而是根据消息的`Routing Key`进行判断，只有队列的`Routingkey`与消息的 `Routing key`完全一致，才会接收到消息



**案例需求如下**：

1. 利用@RabbitListener声明Exchange、Queue、RoutingKey
2. 在consumer服务中，编写两个消费者方法，分别监听direct.queue1和direct.queue2
3. 在publisher中编写测试方法，向itcast. direct发送消息

![image-20220411003159224](assets\image-20220411003159224.png)

#### 使用注解声明交换机

基于@Bean的方式声明队列和交换机比较麻烦，Spring还提供了基于注解方式来声明。

在consumer的SpringRabbitListener中添加两个消费者，同时基于注解来声明队列和交换机：

```java
@RabbitListener(bindings = @QueueBinding(
    value = @Queue(name = "direct.queue1"),
    exchange = @Exchange(name = "itcast.direct", type = ExchangeTypes.DIRECT),
    key = {"red", "blue"}
))
public void listenDirectQueue1(String msg){
    System.out.println("消费者接收到direct.queue1的消息：【" + msg + "】");
}

@RabbitListener(bindings = @QueueBinding(
    value = @Queue(name = "direct.queue2"),
    exchange = @Exchange(name = "itcast.direct", type = ExchangeTypes.DIRECT),
    key = {"red", "yellow"}
))
public void listenDirectQueue2(String msg){
    System.out.println("消费者接收到direct.queue2的消息：【" + msg + "】");
}
```

#### 消息发送

在publisher服务的SpringAmqpTest类中添加测试方法：

```java
@Test
public void testSendDirectExchange() {
    // 交换机名称
    String exchangeName = "itcast.direct";
    // 消息
    String message = "红色警报！日本乱排核废水，导致海洋生物变异，惊现哥斯拉！";
    // 发送消息
    rabbitTemplate.convertAndSend(exchangeName, "red", message);
}
```

#### 总结

描述下Direct交换机与Fanout交换机的差异？

- Fanout交换机将消息路由给每一个与之绑定的队列
- Direct交换机根据RoutingKey判断路由给哪个队列
- 如果多个队列具有相同的RoutingKey，则与Fanout功能类似

基于@RabbitListener注解声明队列和交换机有哪些常见注解？

- @Queue
- @Exchange



### TopicExchange

`Topic`类型的`Exchange`与`Direct`相比，都是可以根据`RoutingKey`把消息路由到不同的队列。只不过`Topic`类型`Exchange`可以让队列在绑定`Routing key` 的时候使用通配符！

```
Routingkey` 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： `item.insert
```

通配符规则：

`#`：匹配一个或多个词

`*`：匹配一个词

举例：

```
item.#`：能够匹配`item.spu.insert` 或者 `item.spu
item.*`：只能匹配`item.spu
```

![image-20220411012107878](assets\image-20220411012107878.png)解释：

- Queue1：绑定的是`china.#` ，因此凡是以 `china.`开头的`routing key` 都会被匹配到。包括china.news和china.weather
- Queue2：绑定的是`#.news` ，因此凡是以 `.news`结尾的 `routing key` 都会被匹配。包括china.news和japan.news



案例需求：

实现思路如下：

1. 并利用@RabbitListener声明Exchange、Queue、RoutingKey
2. 在consumer服务中，编写两个消费者方法，分别监听topic.queue1和topic.queue2
3. 在publisher中编写测试方法，向itcast. topic发送消息

![image-20220411012213082](assets\image-20220411012213082.png)

#### 消息发送

在publisher服务的SpringAmqpTest类中添加测试方法：

```java
/**
     * topicExchange
     */
@Test
public void testSendTopicExchange() {
    // 交换机名称
    String exchangeName = "itcast.topic";
    // 消息
    String message = "喜报！孙悟空大战哥斯拉，胜!";
    // 发送消息
    rabbitTemplate.convertAndSend(exchangeName, "china.news", message);
}
```

#### 消息接收

在consumer服务的SpringRabbitListener中添加方法：

```java
@RabbitListener(bindings = @QueueBinding(
    value = @Queue(name = "topic.queue1"),
    exchange = @Exchange(name = "itcast.topic", type = ExchangeTypes.TOPIC),
    key = "china.#"
))
public void listenTopicQueue1(String msg){
    System.out.println("消费者接收到topic.queue1的消息：【" + msg + "】");
}

@RabbitListener(bindings = @QueueBinding(
    value = @Queue(name = "topic.queue2"),
    exchange = @Exchange(name = "itcast.topic", type = ExchangeTypes.TOPIC),
    key = "#.news"
))
public void listenTopicQueue2(String msg){
    System.out.println("消费者接收到topic.queue2的消息：【" + msg + "】");
}
```

#### 总结

描述下Direct交换机与Topic交换机的差异？

- Topic交换机接收的消息RoutingKey必须是多个单词，以 `**.**` 分割
- Topic交换机与队列绑定时的bindingKey可以指定通配符
- `#`：代表0个或多个词
- `*`：代表1个词



### 消息转换器

之前说过，Spring会把你发送的消息序列化为字节发送给MQ，接收消息的时候，还会把字节反序列化为Java对象。



只不过，默认情况下Spring采用的序列化方式是JDK序列化。众所周知，JDK序列化存在下列问题：

- 数据体积过大
- 有安全漏洞
- 可读性差

我们来测试一下。

#### 测试默认转换器

我们修改消息发送的代码，发送一个Map对象：

```java
@Test
public void testSendMap() throws InterruptedException {
    // 准备消息
    Map<String,Object> msg = new HashMap<>();
    msg.put("name", "Jack");
    msg.put("age", 21);
    // 发送消息
    rabbitTemplate.convertAndSend("simple.queue","", msg);
}
```

停止consumer服务

发送消息后查看控制台：

![image-20220411014112066](assets\image-20220411014112066.png)

它将我们传过去的参数自动进行了序列化

#### 配置JSON转换器

显然，JDK序列化方式并不合适。我们希望消息体的体积更小、可读性更高，因此可以使用JSON方式来做序列化和反序列化。

在publisher和consumer两个服务中都引入依赖：

```xml
<dependency>
    <groupId>com.fasterxml.jackson.dataformat</groupId>
    <artifactId>jackson-dataformat-xml</artifactId>
    <version>2.9.10</version>
</dependency>
```

配置消息转换器。

在启动类中添加一个Bean即可：

```java
@Bean
public MessageConverter jsonMessageConverter(){
    return new Jackson2JsonMessageConverter();
}
```



# ElasticSearch

[ElasticSearch文档](ElasticSearch.md)

